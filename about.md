---
title: About
layout: page
---
![Profile Image]({% if site.external-image %}{{ site.picture }}{% else %}{{ site.url }}/{{ site.picture }}{% endif %})

<p> 
Hi, my name is Chaelin, and I am a PhD student in Computer Science at <a href="https://sse.tulane.edu/">Tulane University</a>, advised by <a href="https://saadh.info/">Prof. Saad Hassan</a>. 
My research interests lie in Human-Computer Interaction (HCI) and Computer Vision, with a particular focus on building AI systems that improve the quality of life for people with disabilities.  </p>

<p> Currently, I am doing research on developing and evaluating AI-based American Sign Language (ASL) learning system for Deaf and Hard of Hearing community. I am focusing on exploring the impact on automatically segmenting signs from long ASL signing videos and evaluating both the accuracy and user experience of this assistive technology.</p>

<p> 
I am currently seeking a summer internship where I can apply my technical expertise and research experience to real-world challenges.

My ultimate goal as a researcher is to create sustainable assistive technologies and systems that can make a positive impact across communities. 
</p> 

<p>I received both BS and MS in IT Engineering from Sookmyung Women's University.</p> 

<h2>Recent News</h2>
  <b>ðŸŽ‰ Our poster and demonstration work has been accepted to <b>ASSETS 2025</b>! ðŸŽ‰

	  
<h2>Conference</h2>
<ul class="conference">

        <table>
		<tbody>
  			<tr>
			<td style="padding:20px;width:25%;vertical-align:middle">
			  <img src="/assets/images/w4a.png" style="width:100%; height:auto;" >
			</td>
			<td style="padding:20px;width:75%;vertical-align:middle">
			  <papertitle> <a href="https://arxiv.org/abs/2504.05857"> Towards an AI-Driven Video-Based American Sign Language Dictionary: Exploring Design and Usage Experience with Learners</a></papertitle>
			  	
			  <br> Saad Hassan, Matyas Bohacek, Chaelin Kim, Denise Crochet
			  <br> The 22nd International Web for All Conference (W4A 2025)

			</td>
			  </tr>    
  			<tr>
			<td style="padding:20px;width:25%;vertical-align:middle">
			  <img src="/assets/images/proposed_model.jpg" style="width:100%; height:auto;" >
			</td>
			<td style="padding:20px;width:75%;vertical-align:middle">
			  <papertitle> <a href="https://ieeexplore.ieee.org/abstract/document/10444505">Channel Selective Relation Network for Efficient Few-shot Facial Expression Recognition</a></papertitle>
			 	
			  <br> Chae-Lin Kim, Ga-Eun Lee, Jiwoo Kang, Byung-Gyu Kim
			  <br> IEEE International Conference on Consumer Electronics (ICCE) 2024

			</td>
			</tr>   
		</tbody>
        </table>



</ul>

<h2>Journal</h2>
<ul class="journal">
        <table>
		<tbody>
			<tr>
			  <td style="padding:20px;width:25%;vertical-align:middle">
				<img src="/assets/images/survey_fer.png" style="width:100%; height:auto;" >
			  </td>
			  <td style="padding:20px;width:75%;vertical-align:middle">
				<papertitle><a href="https://link.springer.com/article/10.1007/s11554-023-01310-x">Few-shot Learning on Facial Expression Recognition: A Comprehensive Survey</a></papertitle>
				
				<br> Chae Lin Kim, Byung-Gyu Kim

		        <br> Journal of Real-Time Image Processing (Springer Nature), vol. 20:52 (Article number: 52), pp. 1-18, May 06, 2023
			  </td>
			</tr>          
		</tbody>
 	</table>

</ul>


<h2>Skills</h2>
<ul class="skills">
	<li>Python</li>
</ul>

<h2>Projects</h2>

<ul>
	<li><a href="https://github.com/">Lorem Lorem</a></li>
	<li><a href="https://github.com/">Ipsum Dolor</a></li>
	<li><a href="https://github.com/">Dolor Lorem</a></li>
</ul>
