---
title:  "[논문정리📃] Learning Transferable Architectures for Scalable Image Recognition"
excerpt: "Week7 -NASNet-"

categories:
  - CNN
  - paperReview
tags: [CNN, paperReview]
use_math: true

last_modified_at: 2021-08-25T08:06:00-05:00
classes: wide
---

## Learning Transferable Architectures for Scalable Image Recognition
#### - NASNet - 

[논문원본](https://arxiv.org/pdf/1707.07012.pdf)😙

NASNet 코드구현 페이지 =>[NASNet](   )

<br>

## 1. Introduction

이 논문에서는 convolution 구조를 디자인하고 데이터셋의 구조를 최적화시키기위한 새로운 패러다임인 
NAS framework를 제시한다. 

NAS framework 
       강화학습을 사용해 구조를 최적화하는 프레임워크

- 기존에 사람이 conv block을 만들었다면 NASNet은 강화학습과 RNN을 활용해 block을 설계함
Search space에 있는 모든 convolutional networks는 weight만 다른, 동일한 구조의 convolutional layers를 가진다.
이렇게  최적의 cell 구조만 찾아내면 되는 간단한 문제가 된다. 이런 방식은 2가지 장점이 있다.
    (1) 전체 네트워크구조를 찾는 것 보다 빠르다.
    (2)  cell 자체가 다른 문제들 보다 잘 일반화 될 수 있다.

“CIFAR-10에서 NASNet(최적의구조)를 찾아내었고,
	                            	 큰 변경없이 ImageNet에 전이시켜 *SOTA 정확도를 가져왔다.”


										*State-Of-The-Art
## 2. Related work
이 논문에서 제시한 방법은 이전의 방식인 hyperparameter optimization과 관련이 있다. 특히, Neural Fabrics, DiffRNN, MetaQNN, DeepArchitect와 같은 최근의 아키텍쳐를 고안하는 접근방식에 관련이 있다.

Evolutionary Algorithms도 구조 설계와 관련이 있지만 large scale에서는 그다지 좋은 결과는 없음

다른 neural network 와 interact 시키거나 metadata로 학습하는 방법이 최근 주목받는다. 대부분의 이 방식은 ImageNet과 같은 large scale데이터에서 적용하지 않음

Search space의 설계는 LSTM과 Neural Architecture Search Cell에서 영감을 받음

VGG, Inception, ResNet/ResNext, Xception/MobileNet은 convolutional cell의 모듈러 구조와 관련이 있음.

## 3. Method

- nasnet framework
![image](https://user-images.githubusercontent.com/53431568/130793437-1c1c3fa9-47b8-4946-a60b-cbee16d80199.png)


ControllerRNN이 search space에 있는 확률값 p 로부터 아키텍쳐(샘플모델 A)를 예측한다. 이때 A는 특정 validation set에 대해 정확도 R을 가질 수 있도록 학습된다. 최종 정확도는 controller가 좋은 모델을 만들어낼 수 있도록 사용된다.

![image](https://user-images.githubusercontent.com/53431568/130793479-8f3c2429-730f-4a6c-89db-b65deb3480ff.png)


- nasnet search space 1

![image](https://user-images.githubusercontent.com/53431568/130793639-945881ee-b267-49b3-8f7b-d20cceeba764.png)


모든  image size에서 쉽게 확장 가능한 구조를 만들기 위해 convolution network는 수동으로 만들며, feature map을 input으로 가져올 때 중요한 일을 수행하는 두 convolutional cell 이 필요하다.

Normal cell : 같은 차원의 feature map 으로 반환
2) Reduction cell : 높이와 너비를 ½ feature map으로 반환


- nasnet search space 2

![image](https://user-images.githubusercontent.com/53431568/130793650-2ab6f0f4-4347-42eb-bca6-9697be82e40e.png)

- imageNet의 image size는 299x299로 32x32 인 CIFAR-10의 구조보다 reduction cell 이 더 많다.

- 이미지 분류 문제의 scale을 맞추기 위해 반복 횟수 N과 initial convolutional filter의 수를 free parameter로 둔다.



- Controller RNN
![image](https://user-images.githubusercontent.com/53431568/130793715-c4ab26ab-3681-4c2f-8414-e497b776f26f.png)



controller RNN에서 Normal cell과 Reduction cell이 찾아지는데, 찾는 과정은 다음과 같다.

 Step 1: hi, hi-1로부터 hidden state 하나를 선택한다 (hi와 hi-1은 이전 블락에서 생성된 hidden state를 의미)
 Step 2: Step 1과 동일하게 두 번째 hidden state 선택.
 Step 3: Step 1에서 선택된 hidden state에 적용할 연산을 선택
 Step 4: Step 2에서 선택된 hidden state에 적용할 연산을 선택
 			     (연산은 아래 목록 중에서 선택!)
           
 ![image](https://user-images.githubusercontent.com/53431568/130793765-ef28cd8c-160b-41cb-8d3c-5b804e551081.png)


 
 Step 5: 새로운 hidden state를 생성하기 위해 Step3과 Step4의 출력 값을 결합할 방법을 선택 
 결합하는 방법은 (1) element-wise addition, (2) concatenation 두 가지 중 하나를 선택
 
 
 
 Step1 ~ Step5 과정을 통해 하나의 블락이 생성된다. 

 그리고 이 프로세스를 5번 반복해 5개의 블락을 생성하고, 5개의 block으로 하나의 Cell을 생성하게 된다.

이 프로세스로 Reduction cell과 Normal Cell을 생성해야 하므로 RNN의 각 레이어는 2x5B Soft max prediction을 한다.  
(처음 5B predictions 은 Normal cell, 두 번째 5B prediction은 Reduction Cell 을 위함)


![image](https://user-images.githubusercontent.com/53431568/130793856-5e511c2e-fdd4-4482-b85b-21e1ebe9041d.png)


<controller RNN 의 작동단계>
 
