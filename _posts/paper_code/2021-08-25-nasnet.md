---
title:  "[ë…¼ë¬¸ì •ë¦¬ğŸ“ƒ] Learning Transferable Architectures for Scalable ImageÂ Recognition"
excerpt: "Week7 -NASNet-"

categories:
  - CNN
  - paperReview
tags: [CNN, paperReview]
use_math: true

last_modified_at: 2021-08-25T08:06:00-05:00
classes: wide
---

## Learning Transferable Architectures for Scalable ImageÂ Recognition
#### - NASNet - 

[ë…¼ë¬¸ì›ë³¸](https://arxiv.org/pdf/1707.07012.pdf)ğŸ˜™

NASNet ì½”ë“œêµ¬í˜„ í˜ì´ì§€ =>[NASNet](   )

<br>

## 1. Introduction

ì´ ë…¼ë¬¸ì—ì„œëŠ” convolution êµ¬ì¡°ë¥¼ ë””ìì¸í•˜ê³  ë°ì´í„°ì…‹ì˜ êµ¬ì¡°ë¥¼ ìµœì í™”ì‹œí‚¤ê¸°ìœ„í•œ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì¸ 
NAS frameworkë¥¼ ì œì‹œí•œë‹¤. 

NAS framework 
       ê°•í™”í•™ìŠµì„ ì‚¬ìš©í•´ êµ¬ì¡°ë¥¼ ìµœì í™”í•˜ëŠ” í”„ë ˆì„ì›Œí¬

- ê¸°ì¡´ì— ì‚¬ëŒì´ conv blockì„ ë§Œë“¤ì—ˆë‹¤ë©´ NASNetì€ ê°•í™”í•™ìŠµê³¼ RNNì„ í™œìš©í•´ blockì„ ì„¤ê³„í•¨
Search spaceì— ìˆëŠ” ëª¨ë“  convolutional networksëŠ” weightë§Œ ë‹¤ë¥¸, ë™ì¼í•œ êµ¬ì¡°ì˜ convolutional layersë¥¼ ê°€ì§„ë‹¤.
ì´ë ‡ê²Œ  ìµœì ì˜ cell êµ¬ì¡°ë§Œ ì°¾ì•„ë‚´ë©´ ë˜ëŠ” ê°„ë‹¨í•œ ë¬¸ì œê°€ ëœë‹¤. ì´ëŸ° ë°©ì‹ì€ 2ê°€ì§€ ì¥ì ì´ ìˆë‹¤.
    (1) ì „ì²´ ë„¤íŠ¸ì›Œí¬êµ¬ì¡°ë¥¼ ì°¾ëŠ” ê²ƒ ë³´ë‹¤ ë¹ ë¥´ë‹¤.
    (2)  cell ìì²´ê°€ ë‹¤ë¥¸ ë¬¸ì œë“¤ ë³´ë‹¤ ì˜ ì¼ë°˜í™” ë  ìˆ˜ ìˆë‹¤.

â€œCIFAR-10ì—ì„œ NASNet(ìµœì ì˜êµ¬ì¡°)ë¥¼ ì°¾ì•„ë‚´ì—ˆê³ ,
	                            	 í° ë³€ê²½ì—†ì´ ImageNetì— ì „ì´ì‹œì¼œ *SOTA ì •í™•ë„ë¥¼ ê°€ì ¸ì™”ë‹¤.â€


										*State-Of-The-Art
## 2. Related work
ì´ ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ ë°©ë²•ì€ ì´ì „ì˜ ë°©ì‹ì¸ hyperparameter optimizationê³¼ ê´€ë ¨ì´ ìˆë‹¤. íŠ¹íˆ, Neural Fabrics, DiffRNN, MetaQNN, DeepArchitectì™€ ê°™ì€ ìµœê·¼ì˜ ì•„í‚¤í…ì³ë¥¼ ê³ ì•ˆí•˜ëŠ” ì ‘ê·¼ë°©ì‹ì— ê´€ë ¨ì´ ìˆë‹¤.

Evolutionary Algorithmsë„ êµ¬ì¡° ì„¤ê³„ì™€ ê´€ë ¨ì´ ìˆì§€ë§Œ large scaleì—ì„œëŠ” ê·¸ë‹¤ì§€ ì¢‹ì€ ê²°ê³¼ëŠ” ì—†ìŒ

ë‹¤ë¥¸ neural network ì™€ interact ì‹œí‚¤ê±°ë‚˜ metadataë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì´ ìµœê·¼ ì£¼ëª©ë°›ëŠ”ë‹¤. ëŒ€ë¶€ë¶„ì˜ ì´ ë°©ì‹ì€ ImageNetê³¼ ê°™ì€ large scaleë°ì´í„°ì—ì„œ ì ìš©í•˜ì§€ ì•ŠìŒ

Search spaceì˜ ì„¤ê³„ëŠ” LSTMê³¼ Neural Architecture Search Cellì—ì„œ ì˜ê°ì„ ë°›ìŒ

VGG, Inception, ResNet/ResNext, Xception/MobileNetì€ convolutional cellì˜ ëª¨ë“ˆëŸ¬ êµ¬ì¡°ì™€ ê´€ë ¨ì´ ìˆìŒ.

## 3. Method

- nasnet framework
![image](https://user-images.githubusercontent.com/53431568/130793437-1c1c3fa9-47b8-4946-a60b-cbee16d80199.png)


ControllerRNNì´ search spaceì— ìˆëŠ” í™•ë¥ ê°’ p ë¡œë¶€í„° ì•„í‚¤í…ì³(ìƒ˜í”Œëª¨ë¸ A)ë¥¼ ì˜ˆì¸¡í•œë‹¤. ì´ë•Œ AëŠ” íŠ¹ì • validation setì— ëŒ€í•´ ì •í™•ë„ Rì„ ê°€ì§ˆ ìˆ˜ ìˆë„ë¡ í•™ìŠµëœë‹¤. ìµœì¢… ì •í™•ë„ëŠ” controllerê°€ ì¢‹ì€ ëª¨ë¸ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆë„ë¡ ì‚¬ìš©ëœë‹¤.

![image](https://user-images.githubusercontent.com/53431568/130793479-8f3c2429-730f-4a6c-89db-b65deb3480ff.png)


- nasnet search space 1

![image](https://user-images.githubusercontent.com/53431568/130793639-945881ee-b267-49b3-8f7b-d20cceeba764.png)


ëª¨ë“   image sizeì—ì„œ ì‰½ê²Œ í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ convolution networkëŠ” ìˆ˜ë™ìœ¼ë¡œ ë§Œë“¤ë©°, feature mapì„ inputìœ¼ë¡œ ê°€ì ¸ì˜¬ ë•Œ ì¤‘ìš”í•œ ì¼ì„ ìˆ˜í–‰í•˜ëŠ” ë‘ convolutional cell ì´ í•„ìš”í•˜ë‹¤.

Normal cell : ê°™ì€ ì°¨ì›ì˜ feature map ìœ¼ë¡œ ë°˜í™˜
2) Reduction cell : ë†’ì´ì™€ ë„ˆë¹„ë¥¼ Â½ feature mapìœ¼ë¡œ ë°˜í™˜


- nasnet search space 2

![image](https://user-images.githubusercontent.com/53431568/130793650-2ab6f0f4-4347-42eb-bca6-9697be82e40e.png)

- imageNetì˜ image sizeëŠ” 299x299ë¡œ 32x32 ì¸ CIFAR-10ì˜ êµ¬ì¡°ë³´ë‹¤ reduction cell ì´ ë” ë§ë‹¤.

- ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì˜ scaleì„ ë§ì¶”ê¸° ìœ„í•´ ë°˜ë³µ íšŸìˆ˜ Nê³¼ initial convolutional filterì˜ ìˆ˜ë¥¼ free parameterë¡œ ë‘”ë‹¤.



- Controller RNN
![image](https://user-images.githubusercontent.com/53431568/130793715-c4ab26ab-3681-4c2f-8414-e497b776f26f.png)



controller RNNì—ì„œ Normal cellê³¼ Reduction cellì´ ì°¾ì•„ì§€ëŠ”ë°, ì°¾ëŠ” ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

Â Step 1: hi, hi-1ë¡œë¶€í„° hidden state í•˜ë‚˜ë¥¼ ì„ íƒí•œë‹¤ (hiì™€ hi-1ì€ ì´ì „ ë¸”ë½ì—ì„œ ìƒì„±ëœ hidden stateë¥¼ ì˜ë¯¸)
Â Step 2: Step 1ê³¼ ë™ì¼í•˜ê²Œ ë‘ ë²ˆì§¸ hidden state ì„ íƒ.
Â Step 3: Step 1ì—ì„œ ì„ íƒëœ hidden stateì— ì ìš©í•  ì—°ì‚°ì„ ì„ íƒ
Â Step 4: Step 2ì—ì„œ ì„ íƒëœ hidden stateì— ì ìš©í•  ì—°ì‚°ì„ ì„ íƒ
 			     (ì—°ì‚°ì€ ì•„ë˜ ëª©ë¡ ì¤‘ì—ì„œ ì„ íƒ!)
           
 ![image](https://user-images.githubusercontent.com/53431568/130793765-ef28cd8c-160b-41cb-8d3c-5b804e551081.png)


 
 Step 5: ìƒˆë¡œìš´ hidden stateë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ Step3ê³¼ Step4ì˜ ì¶œë ¥ ê°’ì„ ê²°í•©í•  ë°©ë²•ì„ ì„ íƒ 
 ê²°í•©í•˜ëŠ” ë°©ë²•ì€ (1) element-wise addition, (2) concatenation ë‘ ê°€ì§€ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ
 
 
 
Â Step1 ~ Step5 ê³¼ì •ì„ í†µí•´ í•˜ë‚˜ì˜ ë¸”ë½ì´ ìƒì„±ëœë‹¤. 

 ê·¸ë¦¬ê³  ì´ í”„ë¡œì„¸ìŠ¤ë¥¼ 5ë²ˆ ë°˜ë³µí•´ 5ê°œì˜ ë¸”ë½ì„ ìƒì„±í•˜ê³ , 5ê°œì˜ blockìœ¼ë¡œ í•˜ë‚˜ì˜ Cellì„ ìƒì„±í•˜ê²Œ ëœë‹¤.

ì´ í”„ë¡œì„¸ìŠ¤ë¡œ Reduction cellê³¼ Normal Cellì„ ìƒì„±í•´ì•¼ í•˜ë¯€ë¡œ RNNì˜ ê° ë ˆì´ì–´ëŠ” 2x5B Soft max predictionì„ í•œë‹¤.  
(ì²˜ìŒ 5B predictions ì€ Normal cell, ë‘ ë²ˆì§¸ 5B predictionì€ Reduction Cell ì„ ìœ„í•¨)


![image](https://user-images.githubusercontent.com/53431568/130793856-5e511c2e-fdd4-4482-b85b-21e1ebe9041d.png)


<controller RNN ì˜ ì‘ë™ë‹¨ê³„>
 
