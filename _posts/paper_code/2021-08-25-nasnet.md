---
title:  "[논문정리📃] Learning Transferable Architectures for Scalable Image Recognition"
excerpt: "Week7 -NASNet-"

categories:
  - paperReview
tags: [CNN, paperReview]
use_math: true

last_modified_at: 2021-08-25T08:06:00-05:00
classes: wide
---

## Learning Transferable Architectures for Scalable Image Recognition
#### - NASNet - 

[논문원본](https://arxiv.org/pdf/1707.07012.pdf)😙

NASNet 코드구현 페이지 =>[NASNet](   )

<br>

## 1. Introduction

이 논문에서는 convolution 구조를 디자인하고 데이터셋의 구조를 최적화시키기위한 새로운 패러다임인 NAS framework를 제시한다. 

> #### NAS framework
> 
> 강화학습을 사용해 구조를 최적화하는 프레임워크

<br>

#### NASNet 특징

- 기존에 사람이 conv block을 만들었다면, NASNet은 강화학습과 RNN을 활용해 block을 설계하였다. 🙌🏻🙌🏻 

- Search space에 있는 모든 convolutional networks는 weight만 다른, 동일한 구조의 convolutional layers를 가진다.

이렇게 최적의 cell 구조만 찾아내면 되는 간단한 문제가 되며, 이 방식은 **2가지 장점**이 있다.

(1) 전체 네트워크구조를 찾는 것 보다 빠르다.

(2) cell 자체가 다른 문제들 보다 잘 일반화 될 수 있다.


#### “CIFAR-10에서 NASNet(최적의구조)를 찾아내었고, 큰 변경없이 ImageNet에 전이시켜 *SOTA 정확도를 가져왔다.”

*State-Of-The-Art


## 2. Related work

- 이 논문에서 제시한 방법은 이전의 방식인 hyperparameter optimization과 관련이 있으며, 특히 Neural Fabrics, DiffRNN, MetaQNN, DeepArchitect와 같은 최근의 아키텍쳐를 고안하는 접근방식에 관련이 있다.

- Evolutionary Algorithms도 구조 설계와 관련이 있지만 large scale에서는 그다지 좋은 결과는 없음

- 다른 neural network 와 interact 시키거나 metadata로 학습하는 방법이 최근 주목받고 있으나 대부분은 ImageNet과 같은 large scale데이터에서 적용하지 않음

- Search space의 설계는 LSTM과 Neural Architecture Search Cell에서 영감을 받음

- VGG, Inception, ResNet/ResNext, Xception/MobileNet은 convolutional cell의 모듈러 구조와 관련이 있음.

## 3. Method

#### 3-1. NAS Overview

![image](https://user-images.githubusercontent.com/53431568/130793437-1c1c3fa9-47b8-4946-a60b-cbee16d80199.png)

위 그림은 NAS의 전체적인 모습을 보여준다. 

먼저, Search Space에 있는 확률값 p로 부터 아키텍쳐(샘플모델 A)를 예측하는데, 이때 A는 특정 Validation set에 대해 R 정확도를 가진다. 이 accuracy값은 controller를 업데이트하기 위해 사용된다. 그럼으로써 controller는 매 순간 더 좋은 구조를 생성하게 됩니다. 

<br>

#### 3-1 Controller RNN

![image](https://user-images.githubusercontent.com/53431568/130793715-c4ab26ab-3681-4c2f-8414-e497b776f26f.png)

controller RNN에서 Normal cell과 Reduction cell을 찾는다.

<br>

#### 3-2 Normal cell, Reduction cell

![image](https://user-images.githubusercontent.com/53431568/130793639-945881ee-b267-49b3-8f7b-d20cceeba764.png)

모든  image size에 적용할 수 있는 구조를 만들기 위해 feature map을 input으로 가져올 때 중요한 일을 수행하는 **두 convolutional cell**이 필요하다.

> 1) Normal cell : 같은 차원의 feature map 으로 반환
> 
> 2) Reduction cell : 높이와 너비를 ½ feature map으로 반환

<br>

![image](https://user-images.githubusercontent.com/53431568/130793650-2ab6f0f4-4347-42eb-bca6-9697be82e40e.png)

- imageNet의 image size는 299x299로 32x32 인 CIFAR-10의 구조보다 크기 때문에 reduction cell 이 더 많다.

- 이미지 분류 문제의 scale을 맞추기 위해 반복 횟수 N과 initial convolutional filter의 수를 free parameter로 둔다.


 <br>
 
#### cell 찾는 방법 😺
 
> Step 1: hi, hi-1로부터 hidden state 하나를 선택한다 (hi와 hi-1은 이전 블락에서 생성된 hidden state를 의미)
> 
> Step 2: Step 1과 동일하게 두 번째 hidden state 선택
> 
> Step 3: Step 1에서 선택된 hidden state에 적용할 연산을 선택
> 
> Step 4: Step 2에서 선택된 hidden state에 적용할 연산을 아래에서 선택한다 
> 
> ![image](https://user-images.githubusercontent.com/53431568/130793765-ef28cd8c-160b-41cb-8d3c-5b804e551081.png)
> 
> Step 5: 새로운 hidden state를 생성하기 위해 Step3과 Step4의 출력 값을 결합할 방법을 선택
> 
> 결합하는 방법은 (1) element-wise addition, (2) concatenation 두 가지 중 하나를 선택한다
 
 
이렇게 Step1 ~ Step5 과정을 통해 하나의 블락이 생성된다. 

그리고 이 프로세스를 5번 반복해 5개의 블락을 생성하고, 5개의 block으로 하나의 Cell을 생성하게 된다.

이 프로세스로 Reduction cell과 Normal Cell을 생성해야 하므로 RNN의 각 레이어는 2x5B Soft max prediction을 한다.  
(처음 5B predictions 은 Normal cell, 두 번째 5B prediction은 Reduction Cell 을 위함)


#### <controller RNN 의 작동단계>

![image](https://user-images.githubusercontent.com/53431568/130793856-5e511c2e-fdd4-4482-b85b-21e1ebe9041d.png)



 
