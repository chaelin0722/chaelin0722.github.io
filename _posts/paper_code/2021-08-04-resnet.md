---
title:  "[논문정리📃] Deep Residual Learning for Image Recognition"
excerpt: "Week5 -VGG16-"

categories:
  - CNN
  - paperReview
tags: [CNN, paperReview]
use_math: true

last_modified_at: 2021-08-04T08:06:00-05:00
classes: wide
---

## Deep Residual Learning for Image Recognition
#### - Resnet - 

[논문원본](https://arxiv.org/pdf/1512.03385.pdf)😙

Resnet56 코드구현 페이지 =>[Resnet-56](https://chaelin0722.github.io/deeplearning/cnn/code/resnet56_cifar10_code/)

<br>

## Abstract
이 논문에서는 더 깊은 neural network일 수록 학습이 어렵다는 것을 감안해 residual learning framework를 제시한다.

residual learning framework는 이전의 네트워크보다 더 깊은 네트워크의 훈련을 용이하게 하기 위한 구조이다.

또, 이 논문을 통해 ImageNet dataset으로 VGG net보다 8배 깊지만 복잡성이 낮은 최대 152개의 layer가 있는 residual net을 평가한다.

ImageNet dataset으로 3.57%의 error율을 보이며 Cifar-10에 대한 분석도 제공한다.

<br>


## 1. Introduction

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   - Degradation

![image](https://user-images.githubusercontent.com/53431568/128124762-2ef0fd37-6591-481b-99eb-f21ff91a5824.png)

최근연구에서는 Layer가 깊을 수록 성능이 더 좋아져야 한다고 주장하지만, 
위의 그래프를 볼 때, 20-layer 보다 56-layer 모델의 각 train, test error rate이 높은 것을 볼 수 있다.

이것이 바로 degradation 이다. (overfitting이 문제가 아니라 model의 깊이가 깊어짐에 따라 train-error가 높아지는 것)

이 문제를 해결하기 위해 본 논문에서는 residual learning 을 제안한다.

<br>

## 2. Architecture
### - Residual learning

![image](https://user-images.githubusercontent.com/53431568/128125059-2fb5d212-0d38-4599-9a88-6e3e9b364fd6.png)

위는 Residual learning의 기본 구조이며 degradation을 해결하기 위해 만들어졌다.

기존에는 H(x)를 출력으로 하는 layer에 대해 W를 업데이트 했다면, residual mapping은 입력 x를 출력 값에 더하는 identity mapping을 수행해 gradient가 잘 흐를 수 있도록 일종의 `shortcut connection`이라는 방법을 사용한다. 

이 shortcut connection은 dimension이 같은 부분에서 수행되는데.. 자세한건 아래 글을 계속 읽어보자!



### - Identity mapping by shortcuts

기본적인 residual block 수식 : $F=W_{2\sigma(W_1x)}$   &nbsp;&nbsp;&nbsp;&nbsp;  ($\sigma$는 ReLu 를 뜻하며, biases는 생략되었다.)

residual block을 정의하는 수식은 x와 F의 dimension이 같은 경우와 다를 경우가 있다.

1. dimension이 같을 때!  &nbsp;&nbsp;   $y=F(x,{W_i}) + x$   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; => **`identity mapping`**
2. dimension이 다를 때!  &nbsp;&nbsp;   $y=F(x, {W_i}) + W_sx$



### - Residual Network

![image](https://user-images.githubusercontent.com/53431568/128128152-a92d7192-9bca-4c19-a175-292cfae05fbd.png)

Residual network 는 `plain network를 기반으로 shortcut connection을 추가한 형태`이다.

residual network에서는 dimension이 증가할 때, 두 가지 옵션을 고려한다.

> (A) identity shortcut connection을 계속 실행하는 경우, dimension을 증가시키기 위해 나머지를 zero padding.
> 
> (B) projection shortcut connection은 dimension을 맞추기 위하여 1X1 connection을 사용.



> (A),(B) 모두 shortcuts이 feature map을 2 size씩 건너뛰기 때문에 stride는 2를 사용한다.


<br>
<hr>
<br>


### 구현과 학습!

이 논문의 resnet은 cifar-10 데이터 셋으로 학습이 가능한데,
논문에서 제시하는 Cifar-10 을 위한 56 layer 의  Resnet으로 구현하였다.

cifar-10 데이터셋 학습 조건은 다음과 같으며 동일하게 수행하였다.


Epoch : 200
BATCH SIZE: 128
Learning rate decay : epoch 구간마다 다름




Resnet56 코드구현 페이지 =>[Resnet-56](https://chaelin0722.github.io/deeplearning/cnn/code/resnet56_cifar10_code/)



<br>


### 참고

[1] [https://jxnjxn.tistory.com/22](https://jxnjxn.tistory.com/22)








