---
title:  "[ë…¼ë¬¸ì •ë¦¬ğŸ“ƒ] An Image is Worth 16X16 Words : Transformers for Image Recognition at Scale"
excerpt: "-vit-"

categories:
  - paperReview
tags: [CNN, paperReview]
use_math: true

last_modified_at: 2021-10-01T08:06:00-05:00
classes: wide
---

## An Image is Worth 16X16 Words : Transformers for Image Recognition at Scale
#### -ViT- 

[ë…¼ë¬¸ì›ë³¸](https://arxiv.org/pdf/2010.11929.pdf)ğŸ˜™

ì˜¤ëŠ˜ì€ Vision Transformerì— ëŒ€í•´ì„œ ë¦¬ë·°í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. Vision Transformer, ì¤„ì—¬ì„œ ViTëŠ” ì›ë˜ ìì—°ì–´ ì²˜ë¦¬(NLP)ì—ì„œ ì‚¬ìš©í•˜ë˜ ëª¨ë¸ì„ Vision ìª½ì— ì ìš©í•œ ëª¨ë¸ì…ë‹ˆë‹¤.

`transformer` ê³¼ `attention` ì— ëŒ€í•œ ê°œë…ì´ ë‚˜ì˜¤ëŠ”ë°, [[ë…¼ë¬¸ì •ë¦¬ğŸ“ƒ]Attention is all you need ](https://chaelin0722.github.io/paperreview/attention/)ë¥¼ ë¨¼ì € ì½ì–´ë³´ë©´ Vision transformerì— ëŒ€í•´ ì´í•´í•˜ê¸° ìˆ˜ì›” í•  ê²ƒì…ë‹ˆë‹¤. :) 


[Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf) ë…¼ë¬¸ ë§í¬ë„ ê±¸ì–´ë‘ê² ìŠµë‹ˆë‹¤!


## ğŸŒ• Abstract


NLP ì—ì„œ 100B ì˜ íŒŒë¼ë¯¸í„°ê°€ ë„˜ëŠ” ì‚¬ì´ì¦ˆë¥¼ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ëœ ë°˜ë©´, ì»´í“¨í„° ë¹„ì „ìª½ì—ì„œëŠ” ì•„ì§ CNN êµ¬ì¡°ê°€ ì£¼ë¥¼ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ° NLPì˜ ì„±ê³µì— ì˜í–¥ì„ ë°›ì•„ ì´ë¯¸ì§€ì— ì§ì ‘ì ìœ¼ë¡œ Transformerì„ ì ìš©í•˜ê³ ì í•˜ì˜€ê³ , transformerì„ ì ìš©í•˜ì—¬ ViTëŠ” ì—„ì²­ë‚œ í¬ê¸°ì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ SOTAë¥¼ ë‹¬ì„±í•˜ëŠ”ë° ì„±ê³µí•©ë‹ˆë‹¤.

í”„ë¡œì„¸ìŠ¤ë¥¼ ê°„ë‹¨íˆ ì‚´í´ë³´ë©´,

  ìì—°ì–´ì—ì„œ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ í† í°ìœ¼ë¡œ ìª¼ê°œì–´ ê°ê°ì„ ì…ë ¥ê°’ìœ¼ë¡œ í•´ì„œ ì§„í–‰í•˜ëŠ” ê²ƒ ì²˜ëŸ¼ vision ìª½ì—ì„œë„ ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ ë‹¨ìœ„ë¡œ ìª¼ê°œì–´ì„œ ê°œë³„ì ìœ¼ë¡œ ì…ë ¥ì„ ë„£ì–´ ì²˜ë¦¬í•´ ì§„í–‰í•˜ê²Œ ë˜ëŠ”ë°


í•œí¸, transformerì„ ì»´í“¨í„° ë¹„ì „ì— ì ìš©í•˜ê¸°ì—ëŠ” `inductive bias`ë¥¼ ê°–ê³  ìˆìŠµë‹ˆë‹¤. inductive biasëŠ” CNNì„ ì‚¬ìš©í•  ë•Œ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ì œì¸ë°, CNNì€ locality í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  
convolutionì—°ì‚°ì€ translation equivarianceì™€ localityí•˜ë‹¤ëŠ” íŠ¹ì§•ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤.

> equivariance ë€, í•¨ìˆ˜ ì…ë ¥ì´ ë°”ë€Œë©´ ì¶œë ¥ ë˜í•œ ë°”ë€ë‹¤ëŠ” ëœ»ì´ë©°, translation equivarianceëŠ” ì…ë ¥ ìœ„ì¹˜ê°€ ë³€í•˜ë©´ ì¶œë ¥ë„ ë§ˆì°¬ê°€ì§€ë¡œ ìœ„ì¹˜ê°€ ë³€í•œì±„ë¡œ ë‚˜ì˜¨ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.
> 
> locality ë€, ì´ë¯¸ì§€ë¥¼ êµ¬ì„±í•˜ëŠ” íŠ¹ì§•ë“¤ì€ ì´ë¯¸ì§€ ì „ì²´ê°€ ì•„ë‹Œ ì¼ë¶€ ì§€ì—­ì— ê·¼ì ‘í•œ í”½ì…€ë“¤ë¡œë§Œ êµ¬ì„±ë˜ê³ , ê·¼ì ‘í•œ í”½ì…€ë“¤ë¼ë¦¬ë§Œ ì¢…ì†ì„±ì„ ê°€ì§„ë‹¤ëŠ” ì„±ì§ˆì…ë‹ˆë‹¤.

ë”°ë¼ì„œ, ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ë¡œ ìª¼ê°œê³  í•™ìŠµí•˜ëŠ”ë°, ê° í”½ì…€ë“¤ì˜ ìœ„ì¹˜ì™€ ì£¼ë³€ ê°’ë“¤ì´ ì¤‘ìš”í•œ CNNì— ìˆì–´ì„œ, ì´ íŒ¨ì¹˜ë“¤ì˜ ì…ë ¥ì´ 1ì°¨ì›ì˜ ê°’ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬ê°€ ëœë‹¤ë©´ ì›í•˜ëŠ” ì¶œë ¥ì´ ë‚˜ì˜¬ ìˆ˜ ì—†ê²Œ ëœë‹¤ëŠ” ëœ»ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ!, ì´ ë…¼ë¬¸ì—ì„œëŠ” `ì—„ì²­ë‚œ ì–‘ì˜ ë°ì´í„°`ë¥¼ ì‚¬ìš©í•´ ì´ inductive biasë¥¼ ì—†ì•¨ ìˆ˜ ìˆì—ˆë‹¤ê³  ë§í•©ë‹ˆë‹¤. ê²°êµ­.. ë°ì´í„°ê°€ ë§ì€ê²Œ í•œìˆ˜ ì˜€ë‚˜ë´…ë‹ˆë‹¤.ğŸ±

![image](https://user-images.githubusercontent.com/53431568/137475377-8963dd9f-ef71-4fb3-8442-3501b7cb5fa5.png)

<br>

## ğŸŒ• Method

![image](https://user-images.githubusercontent.com/53431568/137476320-7b2d4e24-b85d-4a3d-ae88-344973634366.png)


ìœ„ì˜ ì´ë¯¸ì§€ì™€ ê°™ì´ ì´ë¯¸ì§€ë¥¼ ì¼ì •í•œ ê°’ì˜ patchë¡œ ë¶„í• í•˜ê³  ì´ patch ë“¤ì„ embeddingì„ ì‹œì¼œì„œ transformerì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤. ê°œë³„ì˜ patchë¥¼ NLPì˜ token ì²˜ëŸ¼ ê°„ì£¼í•˜ëŠ” ê²ƒì´ì£ .


í”„ë¡œì„¸ìŠ¤ë¥¼ ìì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

![image](https://user-images.githubusercontent.com/53431568/137476415-7611a0fb-3da0-42fb-a617-10fd83e78519.png)

ë¨¼ì € 48x48ì˜ ì´ë¯¸ì§€ë¥¼ input imageë¡œ í•œë‹¤ë©´, (16x16) * 3 ì˜ í˜•íƒœë¡œ ì´ 9ê°œì˜ patch í˜•íƒœë¡œ ìª¼ê°­ë‹ˆë‹¤. ê·¸ë¦¬ê³  ê°ê°ì˜ patchë“¤ì„ linear í•˜ê²Œ ì ìš©ì‹œì¼œì„œ patch embeddingì„ ì§„í–‰í•©ë‹ˆë‹¤. ë”°ë¼ì„œ 768ì°¨ì›ì˜ í•˜ë‚˜ì˜ ë²¡í„°ê°€ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

16x16x3 = 768 = D


<br>

![image](https://user-images.githubusercontent.com/53431568/137476446-1886974b-c6e4-4d02-a44a-3c7130eba869.png)

ê·¸ ë‹¤ìŒì—ëŠ” ê°ê°ì˜ embeddingëœ íŒ¨ì¹˜ì— PE(position embedding) ë¥¼ ë”í•´ì¤€ ê°’ì„ ìµœì¢… transformerì˜ ì…ë ¥ ë²¡í„°ë¡œ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.
ì´ë•Œ, ë§¨ ì•ì—ëŠ” CLASS TOKEN ì´ë¼ëŠ” ê²ƒì´ ë¶™ëŠ”ë°ìš”, ìì—°ì–´ ì²˜ë¦¬ì˜ BERT ëª¨ë¸ì—ì„œ ë‚˜ì˜¨ ê°œë…ì„ ì‚¬ìš©í•œ ê²ƒì…ë‹ˆë‹¤. class tokenì€ BERTì˜ [CLS]í† í°ê³¼ ìœ ì‚¬í•˜ê²Œ, 
Output vector will be used for Image representation for classification
![image](https://user-images.githubusercontent.com/53431568/137478559-a26f1fa6-32c8-43af-9fef-2a242e6676bb.png)



#### ì°¸ê³ 

[1] [inductive bias](https://seongkyun.github.io/study/2019/10/27/cnn_stationarity/)

[2] [https://www.youtube.com/watch?v=bgsYOGhpxDc](https://www.youtube.com/watch?v=bgsYOGhpxDc)
