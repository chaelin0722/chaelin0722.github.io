---
title:  "[논문정리] ImageNet Classification with Deep Convolutional Neural Networks"
excerpt: "Week2 논문요약정리"

categories:
  - CNN
  - paperReview
tags:
  - CNN
last_modified_at: 2021-05-28T08:06:00-05:00
classes: wide
---


[논문원본](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
2012 ILSVRC에서 수상한 neural network **"AlexNet"**

## 0. 요약

ILSVRC-2010 콘테스트에서 ImageNet의 120만 고화질 이미지를 분류하기 위해 크고 깊은 CNN을 사용해 1000개의 다른 클래스들을 도출하였다.

60million 파라미터와 650000 neurons, 5개의 convolutional layers,  max-pooling layers 그리고 3개의 fully-connected layers

- To train faster ⇒ use non-saturating neurons and 효율적인 GPU
- To reduce ⇒ use dropout, which is a recently-developed regularization method

top-5 test error rate of 15.3%를 기록하며 ILSVRC-2012 대회에서 1등을 수상하였다.

## 1. 개요

이전에는 레이블된 이미지 데이터셋은 매우 적었다. 또한 이런 데이터셋은 단순인식 문제에서만 잘 적용이 되었다. 하지만 지금은 수백만개의 이미지로 레이블링 된 데이터 셋을 수집 가능하다.

하지만,

엄청 복잡한 사물 인식 문제는 ImageNet만큼 큰 데이터셋에도 불구하고 구체화 되지 않는다.

따라서 모델은 많은 사전 지식과 아직 가지고 있지 않은 모든 데이터(학습되지 않은 데이터)를 이해해야 한다.

CNN은 깊이와 넓이를 다양하게 컨트롤할 수 있고 강하게도 만들 수 있다. 또한, 자연의 이미지에 대해서 거의 대부분 맞는 예측을 한다. 따라서 기존의 feed-forward neural networks와 비교했을 때 CNN은 더 적은 연결과 파라미터를 가지고 있어 쉽게 학습할 수 있으며 동시에 이론적으로 아주 미미하게 나쁘며 최고의 성능을 낸다

1) CNN의 질과 2)지역적 구조의 상대적 효율에도 불구하고 큰 스케일에서 고 화질을 적용하기에는 여전히 비용이 꽤 든다. 다행히 현재 GPU(highly-optimized implementation of 2D convolution으로 쌍을 이루는 GPU)로 성능을 낼 수 있다.

우리는 이 모델을 통해서 성능을 높이고 학습 시간을 줄였다. 우리의 실험은 성능이 더 좋은 GPU가 발명됨으로써 더 향상될 수 있다.

### 2. Dataset

ImageNet을 사용, 이 시스템에서는 일정한 입력 dimension값이 필요하므로 가변해상도 이미지로 구성된 ImageNet 데이터들을 256의 해상도로 다운 샘플링하였다. 또, 직사각형 이미지가 입력으로 들어올 경우 길이가 짧은 쪽에 rescale을 진행해 가운데로 맞추고 진행하였다. 각 픽셀에서 훈련 set에 대한 평균을 빼는 방법으로만 이미지를 사전처리하였다. 따라서 이 모델에서는 raw RGB 값의 픽셀로 학습을 진행하였다.

### 3. The Architecture

![image](https://user-images.githubusercontent.com/53431568/119877176-a7a1d300-bf63-11eb-8839-061d7750c517.png)

총 8개의 layer로, 5개의 convolutional layer, 3개의 fully-connected layer로 구성되어있다.

### 3.1 ReLU nonlinearity

개념 정리 먼저!

- saturating linearity : 어떤 입력 x가 무한대로 갈 때 함수 값이 무한대로 가는 것 ex) LeRu
- non-saturating linearity : 어떤 입력 x가 무한대로 갈 때 함수 값이 어떤 범위 내에서만 움직이는 것 ex) Sigmoid, hyper tahn

![image](https://user-images.githubusercontent.com/53431568/119877228-bab4a300-bf63-11eb-8304-59a2175bc694.png)

위의 표를 보면, 실선인 ReLu 함수가 점선  tanh 함수보타 약 6배 빠르게 학습할 수 있다는 것을 볼 수 있다. 이것은, 전통모델을 사용했더라면 이 작업에 대해 큰 neural net 실험이 불가능했음을 보여준다.

**빠른 학습은 큰 규모의 데이터셋으로 이루어진 큰 모델의 성능에 좋은 영향을 미친다.**

### 3.2 Training on Multiple GPUs

120만의 학습 예제는 하나의 GPU로는 너무 크다. 따라서 두개의 GPU를 펼쳐서 망(net)을 엇갈리게 하였다. 


![image](https://user-images.githubusercontent.com/53431568/119877274-ca33ec00-bf63-11eb-98a6-5f016782877b.png)

위의 이미지와 같이 kernel 2개를 동시에 사용(GPU 2개로 분할해서) 또 이것을 cross하게 학습하게 끔 하였다. 

- 최근의 GPU들은 교차 병렬처리가 잘 되어있어 호스트 머신 메모리에 직접 가지 않고도 서로의 메모리를 R/W 할 수 있다.
- 각 커널은 바로 앞 단 layer에서 만 입력을 받는다.
- 연결의 패턴을 고르는 것은 cross-validation의 문제이지만 이것 덕분에 허용 가능한 계산 값의 분수가 나올 때까지 미세 조정이 가능하다.

### 3.3 Local Response Normalization

tahn 이나 sigmoid 함수를 사용하면 saturating을 해야해서 overfitting을 방지하기 위해 입력할때 부터 normalization을 들어간다. 하지만 ReLu는 양수 입력값을 그대로 사용하기 때문에 convolution 이나 pooling시 매우 높은 하나의 픽셀값이 주변의 픽셀에 영향을 미치게 된다. 이것을 방지하기 위해 다른 activation map(kernel)의 같은 위치에 있는 픽셀끼리 normalization을 해주는데 이것이 Local Response Normalization이다.

- 이 정규화는 top-1, top-5 에러비율을 0.4%와 0.3% 로 줄였다.
- 1,2 layer에 사용하며 ReLU 함수 적용 후에 사용한다.

### 3.4 Overlapping Pooling

pooling은 특성맵(feature map)을 줄이기 위해 사용하는 것. 여기서는 overlapping, max pooling 을 사용한다. ⇒ 결과로 overfit이 잘 나오지 않는 것을 발견


![image](https://user-images.githubusercontent.com/53431568/119877326-dc158f00-bf63-11eb-9bb1-538ec3f1eb32.png)

대표적으로 Lenet-5는 non-overlapping, average pooling을 사용하였다. 

### 3.5 Overall Archtecture

![image](https://user-images.githubusercontent.com/53431568/119877176-a7a1d300-bf63-11eb-8839-061d7750c517.png)

AlexNet은 총 8개의 layer로, 5개의 convolutional layer, 3개의 fully-connected layer로 구성되어있다. 2,3,5 번째 convolution layer은 전 단계의 같은 채녈의 특성맵들과 연결되어있는 반면, 3번째 convolution layer은 전 단계의 두 채널의 특성 맵들과 모두 연결되어 있다. 모든 layer는 ReLU함수를 사용하고 마지막 output에만 softmax함수를 적용한다.

이제 각 레이어마다 어떤 작업이 수행되는지 살펴보자. 우선 AlexNet에 입력 되는 것은 227 x 227 x 3 이미지다. (227 x 227 사이즈의 RGB 컬러 이미지) 

**1) 첫번째 레이어(컨볼루션 레이어):** 96개의 11 x 11 x 3 사이즈 커널로 입력 영상을 컨볼루션 해준다. 컨볼루션 보폭(stride)를 4로 설정했고, zero-padding은 사용하지 않았다. zero-padding은 컨볼루션으로 인해 특성맵의 사이즈가 축소되는 것을 방지하기 위해, 또는 축소되는 정도를 줄이기 위해 영상의 가장자리 부분에 0을 추가하는 것이다. 결과적으로 55 x 55 x 96 특성맵(96장의 55 x 55 사이즈 특성맵들)이 산출된다. 그 다음에 ReLU 함수로 활성화해준다. 이어서 3 x 3 overlapping max pooling이 stride 2로 시행된다. 그 결과 27 x 27 x 96 특성맵을 갖게 된다. 그 다음에는 수렴 속도를 높이기 위해 local response normalization이 시행된다. local response normalization은 특성맵의 차원을 변화시키지 않으므로, 특성맵의 크기는 27 x 27 x 96으로 유지된다.

**2) 두번째 레이어(컨볼루션 레이어):** 256개의 5 x 5 x 48 커널을 사용하여 전 단계의 특성맵을 컨볼루션해준다. stride는 1로, zero-padding은 2로 설정했다. 따라서 27 x 27 x 256 특성맵(256장의 27 x 27 사이즈 특성맵들)을 얻게 된다. 역시 ReLU 함수로 활성화한다. 그 다음에 3 x 3 overlapping max pooling을 stride 2로 시행한다. 그 결과 13 x 13 x 256 특성맵을 얻게 된다. 그 후 local response normalization이 시행되고, 특성맵의 크기는 13 x 13 x 256으로 그대로 유지된다.

**3) 세번째 레이어(컨볼루션 레이어):** 384개의 3 x 3 x 256 커널을 사용하여 전 단계의 특성맵을 컨볼루션해준다. stride와 zero-padding 모두 1로 설정한다. 따라서 13 x 13 x 384 특성맵(384장의 13 x 13 사이즈 특성맵들)을 얻게 된다. 

**4) 네번째 레이어(컨볼루션 레이어):** 384개의 3 x 3 x 192 커널을 사용해서 전 단계의 특성맵을 컨볼루션해준다. stride와 zero-padding 모두 1로 설정한다. 따라서 13 x 13 x 384 특성맵(384장의 13 x 13 사이즈 특성맵들)을 얻게 된다. 

**5) 다섯번째 레이어(컨볼루션 레이어):** 256개의 3 x 3 x 192 커널을 사용해서 전 단계의 특성맵을 컨볼루션해준다. stride와 zero-padding 모두 1로 설정한다. 따라서 13 x 13 x 256 특성맵(256장의 13 x 13 사이즈 특성맵들)을 얻게 된다. ReLU로 활성화 후 3 x 3 overlapping max pooling을 stride 2로 시행한다. 그 결과 6 x 6 x 256 특성맵을 얻게 된다.

**6) 여섯번째 레이어(Fully connected layer):** 6 x 6 x 256 특성맵을 flatten해줘서 6 x 6 x 256 = 9216차원의 벡터로 만들어준다. 그것을 여섯번째 레이어의 4096개의 뉴런과 fully connected 해준다. 그 결과를 ReLU 함수로 활성화한다.

**7) 일곱번째 레이어(Fully connected layer):** 4096개의 뉴런으로 구성되어 있다. 전 단계의 4096개 뉴런과 fully connected되어 있다. 

**8) 여덟번째 레이어(Fully connected layer):** 1000개의 뉴런으로 구성되어 있다. 전 단계의 4096개 뉴런과 fully connected되어 있다. 1000개 뉴런의 출력값에 softmax 함수를 적용해 1000개 클래스 각각에 속할 확률을 나타낸다.

### 4. Reducing Overfitting

이 NN의 구조는 6000만개의 파라미터를 갖고있다. 1000개 ILSVRC 클래스들로 인해 각 학습 예제가 이미지부터 레이블까지 매핑할 때 10bit로 제어를 해도 overfitting에 대한 고려 없이 아주 많은 파라미터를 학습시키기에는 불충분한 것으로 밝혀졌다. 두 가지 방법은 다음과 같다.

### 4.1 Data Augmentation

overfitting을 방지하기 위한 아주 기본적인 방법은 레이블을 보존하면서 변환시키는 방법으로 데이터셋을 인공적으로 늘리는 것이다.

  1) 이미지 번역과 수평 반전

  2) RGB 픽셀값의 집합에 PCA 적용

### 4.2 Dropout

예측을 조합하는 것은 좋은 방법이나 오랜 시간이 걸리고 아주 큰 NN에 높은 비용이 발생한다. 따라서 dropout으로 뉴런들간의 복잡한 상호 의존도를 낮추어서 overfitting을 막을 수 있다.  

- "dropout"이라는 것은 forward pass에 관여하지 않고 back propagation에도 참여하지 않는것이다. 단, training할 때만 참여하지 않고 test할 때는 참여해야 한다.

![image](https://user-images.githubusercontent.com/53431568/119877421-fbacb780-bf63-11eb-806b-0eac7302d14f.png)

### 5. Details of learning

그냥 논문 참고해보기.. 

### 6. Results

![image](https://user-images.githubusercontent.com/53431568/119877472-0c5d2d80-bf64-11eb-8374-b46819fd1433.png)

table2에서 보는 바와 같이 경험상 0.1%이상 차이가 나지 않아서. 본 논문에서 설명된 CNN은 top-5 error rate으로 18.2%를 달성한다. 5개의 유사한 CNN의 예측을 평균하면 16.4%의 오류율이 제공된다. 전체 1,500만 이미지, 22K 카테고리를 가진 ImageNet Fall 2011 릴리즈셋을 분류하기 위해 마지막 풀링 계층에다가 6번째 컨볼루션 레이어를 추가한 CNN 모델을 학습시킨다음 ILSVRC-2012에서 fine-tuning하면 error rate이 16.6%가 된다. 전체 2011년 가을 릴리즈 셋에서 앞서 언급한 5개의 CNN으로 pre-trained 된 2개의 CNN의 예측을 평균하면 15.3%의 오류율이 제공된다.

참고

[1] [https://bskyvision.com/421](https://bskyvision.com/421)
