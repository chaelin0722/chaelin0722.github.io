---
title:  "[GAN study] Super Resolution GAN (SRGAN)"
excerpt: ""

categories:
  - gan

tags: [Deeplearning, study, gan]

classes: wide

use_math : true

last_modified_at: 2021-10-06T08:06:00-05:00

---

Gan 학습 로드맵 다섯 번째 시간! 랩미팅 준비로 너무 바빠서 리뷰를 빨리 못했다 ㅎㅎ 더 열심히 해야지 허허😤😤

영어 원문 글은 [여기](https://jonathan-hui.medium.com/gan-super-resolution-gan-srgan-b471da7270ec)로 가면 됩니다! 영어로 공부하고 싶다면 고고~

[SRGAN 논문](https://arxiv.org/pdf/1609.04802.pdf)


<br>

![image](https://user-images.githubusercontent.com/53431568/136047749-1decab72-4817-4209-b502-647c87d5dd87.png)

<br>

![image](https://user-images.githubusercontent.com/53431568/136047821-554e62ad-bb22-428a-bbbe-5c74d793333e.png)


Super-resolution GAN은 고화질의 이미지를 생성하기 위해 deep network를 adversary network와 결합해 적용합니다. 위의 그림과 같이 SRGAN은 
GAN을 사용하지 않는 비슷한 디자인 구조인 SRResNet 과 비교했을 때 더 많은 디테일들로 사람들에게 더 매력적으로 다가오고 있습니다.

학습 동안, 고화질 이미지(HR)는 저화질 이미지로(LR) 다운샘플링 됩니다. GAN 생성자는 저화질(LR)이미지를 고화질(SR)이미지로 업샘플링 시킵니다. 

여기서, 고화질 이미지를 구분하기 위해 구분자를 사용하며, 구분자와 생성자를 학습시키기 위해 GAN loss를 역전파 시키게 됩니다.

![image](https://user-images.githubusercontent.com/53431568/136050709-89ee8951-1de2-4264-9998-8dbfe1e40598.png)


<br>

아래는 generator와 discriminator의 네트워크 구조입니다. 거의 대부분 convolution layer, batch normalization, parameterized ReLU(PRelU)로 이루어져 있습니다.

생성자는 ResNet과 비슷하게 skip connection이 구현되어 있습니다. ("k3n64s1"이 있는 convolution layer은 stride가 1인 64channels 를 출력하는 3X3 커널 필터를 나타냅니다.)

![image](https://user-images.githubusercontent.com/53431568/136051790-ed10d519-7090-45a5-a089-56a6c72b4370.png)



### Loss Function
generator를 위한 손실함수는 content loss(reconstruction loss)와 adversarial loss를 포함하고 있다.

![image](https://user-images.githubusercontent.com/53431568/136052264-b2ca2f0d-b9c9-4795-a51b-d432883943ca.png)



adversarial loss 는 아래와 같이 정의되어 있습니다.

![image](https://user-images.githubusercontent.com/53431568/136052246-9ee02fb7-e698-4912-83b9-a3353b755a45.png)


여기서, content loss pixel-wise를 저화질과 고화질 이미지 사이의 mean square error(MSE)를 사용해 계산하게 됩니다. 이 값이 수학적 거리를 결정하지만 사람들에게는 와 닿지 않습니다.

SRGAN은 VGG-19에서 추출한 feature(특징)의 MSE를 측정할 때, perceptual loss(지각손실)을 사용합니다. 

*VGG-19의 특정 레이어는 그들의 특징(features)이 잘 맞도록 설계되어있다. (Minimum MSE for features)


![1_kJYNx-ah-eFiNywZ854nlw](https://user-images.githubusercontent.com/53431568/136053830-d67ef07c-24d0-4465-90f4-79afbd121cfa.jpeg)


한편, 구분자를 학습하기 위해서는, 전형적인 GAN 구분자 손실함수를 사용합니다.

![1_Kojbd--gkQr_TYG4TSyXnA](https://user-images.githubusercontent.com/53431568/136053868-f034babf-afe1-42e1-9fb2-203120e28985.png)



이번 글은 매우 짧지만 공부하지 않은 개념들이 많아 해석에 어려움이 있네요.. 논문 리뷰를 먼저 한 후에 블로그들을 포스팅하는 방식으로 바꿔야 할 것 같다..!

SRGAN논문도 이후에 포스팅할 예정입니다..! 가자!


[SRGAN 논문을 보고싶다면 여기!](https://arxiv.org/pdf/1609.04802.pdf)



<iframe src="https://giphy.com/embed/kyLYXonQYYfwYDIeZl" width="480" height="360" frameBorder="0" class="giphy-embed" allowFullScreen></iframe>

