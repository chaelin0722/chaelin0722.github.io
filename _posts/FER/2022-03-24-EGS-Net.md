---
title:  "[Paper Review📃] When Facial Expression Recognition Meets Few-Shot Learning: A Joint and Alternate Learning Framework"
excerpt: "-EGS-Net-"

categories:
  - fer
  - few-shot
  
tags: [fer,CNN, paperReview, fewshot]
use_math: true

last_modified_at: 2022-03-24T08:06:00-05:00
classes: wide
---

## When Facial Expression Recognition Meets Few-Shot Learning: A Joint and Alternate Learning Framework
#### -EGS-Net-

[Paper](https://arxiv.org/pdf/2201.06781.pdf)😙 

This paper proposes Emotion guided Similarity Network (EGS-Net), consisting emotion branch and a similarity branch, based on a two-stage learning framework.
In the first stage, the similarity branch is jointly trained with the emotion branch in a multi-task fashion. With the regularization of the emotion branch, we prevent the similarity branch from overfitting to sampled base classes that are highly overlapped across different episodes. In the second stage, the emotion branch and the similarity branch play a two-student game to alternately learn from each other, thereby further improving the inference ability of the similarity branch on `unseen compound expressions.`


Before discuss the whole architecture, let's flick through what is few-shot learning😀

전체적 구조를 살펴보기 전 퓨샷러닝(few-shot) 이 무엇인지 잠깐 훑어봅시다!

for more details about few-shot learning go to this post! -> [what is few-shot learning?](https://chaelin0722.github.io/cnn/few_shot/)

퓨샷에 대한 자세한 내용은 위의 링크 포스트로 gogo~

<br>

#### Few shot learning

This concept is from a thought "Humans learn new concepts with very little supervision!". Previously deep learning tasks have been trained with large-scale datasets like ImageNet and mscoco dataset. Some authors insisted that they are not enough, and they even added JFT-300M, unlabelled large dataset. It was an inevitable problem since long time ago. However, few-shot concept is one of the solutions for large-scale dataset problem. 

In few-shot learning, model performs well with even small scale dataset. Below picture is a example of how it works.

In few shot, they use N classes, not all the classes and use K samples for each class and this is support set.
Let's say we will train 3 classes with 2 samples each. and it is called `"3 way 2 shot learning"`

If you want to learn 2 classes with 1 sample each, it is called "2 way 1 shot learning"

And batch set(or query set) is working as validation set, the model's purpose is to predict query set's sample correctly. 

So, below image shows each train tasks in 3 way 2 shot learning. And for test task, same process as train task but! use `unseen classes` with samples.


![image](https://user-images.githubusercontent.com/53431568/161900569-400d94e1-bcfe-41d2-a38d-e22ead8c3a1e.png)
[이미지출처]https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/

<br>

#### To recapitulate briefly, the main points are..

- Outperforms even with small scale dataset (ex) mini-ImageNet:100 class, 600images each)
- Train with few images, not all
- Possible in inferencing unseen datasets.


#### Now let's move on to EGS-Net!

<img width="753" alt="image" src="https://user-images.githubusercontent.com/53431568/159844246-0ddf3001-e2eb-40f6-80e9-2abaf6f24d21.png">

<br>

### 1st stage : Joint Learning

![image](https://user-images.githubusercontent.com/53431568/161903212-4e60be17-57ee-47ec-8c3b-67f11d296f27.png)

<br>

### Emotion branch

In emotion branch, global representative features are extracted. And this feature used as regularizer for similarity branch.

![image](https://user-images.githubusercontent.com/53431568/161903552-c95eed6d-a749-453c-ac8f-1162cc903b92.png)

<br>

### Similarity branch

This branch is the one using few-shot learning concept. each features from support set and query set are calculated with metric-based computation.(cosine similarity)

![image](https://user-images.githubusercontent.com/53431568/161903382-0689d4ca-1e18-41b4-928c-9237c30d7661.png)

<br>

### 2nd stage : Alternative Learning

![image](https://user-images.githubusercontent.com/53431568/161903587-81573740-17c0-462b-93f6-74fcc8e67f43.png)![image](https://user-images.githubusercontent.com/53431568/161903622-8d78500b-da1a-4225-b6c9-15e5ae305990.png)

<br>

### whole process
![image](https://user-images.githubusercontent.com/53431568/161903684-ebffd8db-e10a-4a0e-98c2-f32f6e58be24.png)

<br>

### setting details

![image](https://user-images.githubusercontent.com/53431568/161903810-bd0324c5-e601-46cf-b5b6-2c541f341653.png)



### Domain shift

> THIS IS ADDITIONAL RESEARCH TO EXPLAIN EXPERIMENT ON THIS PAPER.

that current few-shot learning algorithms are fragile to address a large domain-shift. You can compare three tables below.

![image](https://user-images.githubusercontent.com/53431568/161904419-97edb539-121e-4de7-afc6-e570a1685fb2.png)

As you see, the scenario with a large domain shift mini-ImageNet → CK+ and mini-ImageNet → RAF seems NOT GOOD. However, the scenario with a narrow domain shift: RAF basic → CK+ and the best performing algorithm reached 84.90% ± 0.53% accuracy, when only learning from five samples.

In fact, due to the limited number of base classes in our FER task, the performance of existing FSL methods drops substantially.

=> to alleviate this problem, paper proposed a novel EGS-Net with joint learning + alternate learning

<br>

### Experiments

![image](https://user-images.githubusercontent.com/53431568/161906982-d8d72d6b-72ea-4272-b634-00d7d66022ca.png)

저자는 CFEE와 EmotionNet 두개의 compound emotion이 포함된 데이터셋으로 실험을 진행하였다.  training 에는 기본 감정(6~8개)만 가지고 있기 때문에 디테일한 설정을 보기 위해서 각 테스트 데이터에 \_B(basic emotion), \_C(compound emotion) 으로 나누어서 (CFEE_B CFEE_C, EmotioNet_B, EmotioNet_C) 실험하였다.

그리고 각 E_b 는 emotion branch, S_b 는 similarity branch를 뜻하며 (single)은 RAF-DB 만 사용하였을때, (multiple)는 데이터를 모두 복합적으로 학습시켰을 때를 의미한다. 

확실히 1shot 보다는 5shot 일때 성능이 좋으며, compound emotion 데이터보다 basic emotion 데이터의 성능이 더 좋다. 이는 `domain shift 가 작기 때문`이라고 볼 수 있다.
또한,  single이미지로 학습시킬때는 emotion branch 와 similarity branch의 성능 차이가 적지만 multiple 이미지일 때, similarity branch의 성능이 더 좋아지는 것을 볼 수 있다.(inference ability to unseen data) 이것은 few-shot을 사용하는 것의 타당성을 입증시켜준다고 판단된다. 

<br>

#### references

[1] [Matching Networks for One Shot Learning](https://arxiv.org/abs/1606.04080)

[2] [Revisiting few-shot learning for facial expression recognition](https://arxiv.org/abs/1912.02751)

