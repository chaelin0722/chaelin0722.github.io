---
title:  "[Paper ReviewğŸ“ƒ] When Facial Expression Recognition Meets Few-Shot Learning: A Joint and Alternate Learning Framework"
excerpt: "-EGS-Net-"

categories:
  - fer
  - few-shot
  
tags: [fer,CNN, paperReview, fewshot]
use_math: true

last_modified_at: 2022-03-24T08:06:00-05:00
classes: wide
---

## When Facial Expression Recognition Meets Few-Shot Learning: A Joint and Alternate Learning Framework
#### -EGS-Net-

[Paper](https://arxiv.org/pdf/2201.06781.pdf)ğŸ˜™ 

This paper proposes Emotion guided Similarity Network (EGS-Net), consisting emotion branch and a similarity branch, based on a two-stage learning framework.
In the first stage, the similarity branch is jointly trained with the emotion branch in a multi-task fashion. With the regularization of the emotion branch, we prevent the similarity branch from overfitting to sampled base classes that are highly overlapped across different episodes. In the second stage, the emotion branch and the similarity branch play a two-student game to alternately learn from each other, thereby further improving the inference ability of the similarity branch on `unseen compound expressions.`


Before discuss the whole architecture, let's flick through what is few-shot learningğŸ˜€

ì „ì²´ì  êµ¬ì¡°ë¥¼ ì‚´í´ë³´ê¸° ì „ í“¨ìƒ·ëŸ¬ë‹(few-shot) ì´ ë¬´ì—‡ì¸ì§€ ì ê¹ í›‘ì–´ë´…ì‹œë‹¤!

for more details about few-shot learning go to this post! -> [what is few-shot learning?](https://chaelin0722.github.io/cnn/few_shot/)

í“¨ìƒ·ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ìœ„ì˜ ë§í¬ í¬ìŠ¤íŠ¸ë¡œ gogo~

<br>

#### Few shot learning

This concept is from a thought "Humans learn new concepts with very little supervision!". Previously deep learning tasks have been trained with large-scale datasets like ImageNet and mscoco dataset. Some authors insisted that they are not enough, and they even added JFT-300M, unlabelled large dataset. It was an inevitable problem since long time ago. However, few-shot concept is one of the solutions for large-scale dataset problem. 

In few-shot learning, model performs well with even small scale dataset. Below picture is a example of how it works.

In few shot, they use N classes, not all the classes and use K samples for each class and this is support set.
Let's say we will train 3 classes with 2 samples each. and it is called `"3 way 2 shot learning"`

If you want to learn 2 classes with 1 sample each, it is called "2 way 1 shot learning"

And batch set(or query set) is working as validation set, the model's purpose is to predict query set's sample correctly. 

So, below image shows each train tasks in 3 way 2 shot learning. And for test task, same process as train task but! use `unseen classes` with samples.


![image](https://user-images.githubusercontent.com/53431568/161900569-400d94e1-bcfe-41d2-a38d-e22ead8c3a1e.png)
[ì´ë¯¸ì§€ì¶œì²˜]https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/

<br>

#### To recapitulate briefly, the main points are..

- Outperforms even with small scale dataset (ex) mini-ImageNet:100 class, 600images each)
- Train with few images, not all
- Possible in inferencing unseen datasets.


#### Now let's move on to EGS-Net!

<img width="753" alt="image" src="https://user-images.githubusercontent.com/53431568/159844246-0ddf3001-e2eb-40f6-80e9-2abaf6f24d21.png">

<br>

### 1st stage : Joint Learning

![image](https://user-images.githubusercontent.com/53431568/161903212-4e60be17-57ee-47ec-8c3b-67f11d296f27.png)

<br>

### Emotion branch

In emotion branch, global representative features are extracted. And this feature used as regularizer for similarity branch.

![image](https://user-images.githubusercontent.com/53431568/161903552-c95eed6d-a749-453c-ac8f-1162cc903b92.png)

<br>

### Similarity branch

This branch is the one using few-shot learning concept. each features from support set and query set are calculated with metric-based computation.(cosine similarity)

![image](https://user-images.githubusercontent.com/53431568/161903382-0689d4ca-1e18-41b4-928c-9237c30d7661.png)

<br>

### 2nd stage : Alternative Learning

![image](https://user-images.githubusercontent.com/53431568/161903587-81573740-17c0-462b-93f6-74fcc8e67f43.png)![image](https://user-images.githubusercontent.com/53431568/161903622-8d78500b-da1a-4225-b6c9-15e5ae305990.png)

<br>

### whole process
![image](https://user-images.githubusercontent.com/53431568/161903684-ebffd8db-e10a-4a0e-98c2-f32f6e58be24.png)

<br>

### setting details

![image](https://user-images.githubusercontent.com/53431568/161903810-bd0324c5-e601-46cf-b5b6-2c541f341653.png)



### Domain shift

> THIS IS ADDITIONAL RESEARCH TO EXPLAIN EXPERIMENT ON THIS PAPER.

that current few-shot learning algorithms are fragile to address a large domain-shift. You can compare three tables below.

![image](https://user-images.githubusercontent.com/53431568/161904419-97edb539-121e-4de7-afc6-e570a1685fb2.png)

As you see, the scenario with a large domain shift mini-ImageNet â†’ CK+ and mini-ImageNet â†’ RAF seems NOT GOOD. However, the scenario with a narrow domain shift: RAF basic â†’ CK+ and the best performing algorithm reached 84.90% Â± 0.53% accuracy, when only learning from five samples.

In fact, due to the limited number of base classes in our FER task, the performance of existing FSL methods drops substantially.

=> to alleviate this problem, paper proposed a novel EGS-Net with joint learning + alternate learning

<br>

### Experiments

![image](https://user-images.githubusercontent.com/53431568/161906982-d8d72d6b-72ea-4272-b634-00d7d66022ca.png)

ì €ìëŠ” CFEEì™€ EmotionNet ë‘ê°œì˜ compound emotionì´ í¬í•¨ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ë‹¤.  training ì—ëŠ” ê¸°ë³¸ ê°ì •(6~8ê°œ)ë§Œ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ë””í…Œì¼í•œ ì„¤ì •ì„ ë³´ê¸° ìœ„í•´ì„œ ê° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— \_B(basic emotion), \_C(compound emotion) ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì„œ (CFEE_B CFEE_C, EmotioNet_B, EmotioNet_C) ì‹¤í—˜í•˜ì˜€ë‹¤.

ê·¸ë¦¬ê³  ê° E_b ëŠ” emotion branch, S_b ëŠ” similarity branchë¥¼ ëœ»í•˜ë©° (single)ì€ RAF-DB ë§Œ ì‚¬ìš©í•˜ì˜€ì„ë•Œ, (multiple)ëŠ” ë°ì´í„°ë¥¼ ëª¨ë‘ ë³µí•©ì ìœ¼ë¡œ í•™ìŠµì‹œì¼°ì„ ë•Œë¥¼ ì˜ë¯¸í•œë‹¤. 

í™•ì‹¤íˆ 1shot ë³´ë‹¤ëŠ” 5shot ì¼ë•Œ ì„±ëŠ¥ì´ ì¢‹ìœ¼ë©°, compound emotion ë°ì´í„°ë³´ë‹¤ basic emotion ë°ì´í„°ì˜ ì„±ëŠ¥ì´ ë” ì¢‹ë‹¤. ì´ëŠ” `domain shift ê°€ ì‘ê¸° ë•Œë¬¸`ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.
ë˜í•œ,  singleì´ë¯¸ì§€ë¡œ í•™ìŠµì‹œí‚¬ë•ŒëŠ” emotion branch ì™€ similarity branchì˜ ì„±ëŠ¥ ì°¨ì´ê°€ ì ì§€ë§Œ multiple ì´ë¯¸ì§€ì¼ ë•Œ, similarity branchì˜ ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.(inference ability to unseen data) ì´ê²ƒì€ few-shotì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì˜ íƒ€ë‹¹ì„±ì„ ì…ì¦ì‹œì¼œì¤€ë‹¤ê³  íŒë‹¨ëœë‹¤. 

<br>

#### references

[1] [Matching Networks for One Shot Learning](https://arxiv.org/abs/1606.04080)

[2] [Revisiting few-shot learning for facial expression recognition](https://arxiv.org/abs/1912.02751)

